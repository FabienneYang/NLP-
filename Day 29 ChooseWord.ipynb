{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepocess_line(line):\n",
    "    # 僅僅挑出中文字元，並且斷開不連續的中文字\n",
    "    # YOUR CODE HERE\n",
    "    pattern = r'[\\u4e00-\\u9fff]+'\n",
    "    segments = re.findall(pattern, line)\n",
    "    # END YOUR CODE\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments = []\n",
    "with open('./wiki_zh_small.txt',encoding=\"utf-8\") as fr:\n",
    "    for line in fr.readlines():\n",
    "        segments += prepocess_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['英語', '一詞源於遷居英格蘭的日耳曼部落盎格魯', '而', '盎格魯', '得名於']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepocess_line('“英語”一詞源於遷居英格蘭的日耳曼部落盎格魯（），而“盎格魯”得名於')  \n",
    "# 應該為：['英語', '一詞源於遷居英格蘭的日耳曼部落盎格魯', '而', '盎格魯', '得名於']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['英語',\n",
       " '英語英語',\n",
       " '又稱爲英文',\n",
       " '是一種西日耳曼語言',\n",
       " '誕生於中世紀早期的英格蘭',\n",
       " '如今具有全球通用語的地位',\n",
       " '英語',\n",
       " '一詞源於遷居英格蘭的日耳曼部落盎格魯',\n",
       " '而',\n",
       " '盎格魯']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngram\n",
    "一開始要先計算字詞出現的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#Counter 的 key 是要計數的 item，value 保存的是個數\n",
    "\n",
    "class Counters:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.counters = [Counter() for _ in range(n + 1)]  # 分別代表計算0、1、...個字的出現次數\n",
    "        # _ means Ignore the index\n",
    "\n",
    "    def fit(self, segments):\n",
    "        # 因為 self.counters 分別代表計算0、1、...個字的出現次數\n",
    "        # 請在此實作利用 segments 以及函式 _skip 來統計次數\n",
    "\n",
    "        for i in range(1, 1 + self.n):\n",
    "        # i = 1 ~ 第 n+1 個字\n",
    "            for seg in tqdm(segments):\n",
    "                self.counters[i] += Counter(self._skip(seg,i))\n",
    "                # seg中每個字出現次數 = Counter(self._skip(seg, i))\n",
    "                \n",
    "        count = sum(dict(self.counters[1]).values()) # 計算字的總數\n",
    "        self.counters[0] = Counter({'': count}) # 新增一欄來計算總數\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, k):\n",
    "        return self.counters[k]\n",
    "\n",
    "    def _skip(self, segment, n):\n",
    "        assert n > 0 #指的是程式進行到某個時間點，斷定其必然是某種狀態。這裡指必須是大於 0 的正數\n",
    "        if len(segment) < n:\n",
    "            return []\n",
    "        shift = n - 1\n",
    "        for i in range(len(segment) - shift):\n",
    "            yield segment[i:i+shift+1] #丟出值並暫時停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 48767/48767 [00:13<00:00, 3638.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 48767/48767 [07:05<00:00, 114.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 48767/48767 [13:11<00:00, 61.59it/s]\n"
     ]
    }
   ],
   "source": [
    "counters = Counters(n=3)\n",
    "counters.fit(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'': 371373})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counters[1]['英']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ngram:\n",
    "    def __init__(self, n, counters):\n",
    "        assert n <= counters.n\n",
    "        self.n = n\n",
    "        self.major_counter = counters[n]\n",
    "        self.minor_counter = counters[n-1]\n",
    "\n",
    "    def predict_proba(self, prefix='', top_k=5):\n",
    "        assert len(prefix) >= self.n - 1\n",
    "        # 使用 Ngram 的公式計算出下一個字出現的機率\n",
    "        # 輸出為機率與字的tuple列表，詳見下方輸出範例\n",
    "        if self.n > 1:\n",
    "            pre = prefix[-(self.n - 1):]\n",
    "        else:\n",
    "            pre = ''\n",
    "            \n",
    "        count_pre = self.minor_counter[pre]\n",
    "        probs = []\n",
    "        for k, count in dict(self.major_counter).items():\n",
    "            if k.startswith(pre):\n",
    "                prob = count / count_pre\n",
    "                probs.append((prob, k[-1]))\n",
    "        \n",
    "        sorted_probs = sorted(probs, reverse=True)\n",
    "\n",
    "        return sorted_probs[:top_k] if top_k > 0 else sorted_probs\n",
    "\n",
    "    def get_proba_dict(self, prefix=''):\n",
    "        return {word: prob for prob, word in self.predict_proba(prefix, top_k=-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram = Ngram(1, counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.035732269174118744, '的'),\n",
       " (0.012927703414087723, '國'),\n",
       " (0.010620050461395955, '中'),\n",
       " (0.009984570768472667, '在'),\n",
       " (0.009852627950874188, '一')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.predict_proba('我思')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram = Ngram(2, counters)\n",
    "trigram = Ngram(3, counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Ngram來建立第一版選字系統"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ChineseWordRecommenderV1:\n",
    "    def __init__(self, unigram, bigram, trigram):\n",
    "        self.unigram = unigram\n",
    "        self.bigram = bigram\n",
    "        self.trigram = trigram\n",
    "    \n",
    "    def predict_proba(self, prefix='', top_k=5):\n",
    "        # 使用Ngram來建立選字系統\n",
    "        if not prefix:\n",
    "            return self.unigram.predict_proba(prefix, top_k)\n",
    "        elif len(prefix) == 1:\n",
    "            return self.bigram.predict_proba(prefix, top_k)\n",
    "        else:\n",
    "            return self.trigram.predict_proba(prefix, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ChineseWordRecommenderV1(unigram, bigram, trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.75, '故'), (0.25, '維')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict_proba('我思', top_k=10)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\fabienne\\anaconda3\\lib\\site-packages (20.3.4)\n",
      "Collecting pip\n",
      "  Using cached pip-20.3.4-py2.py3-none-any.whl (1.5 MB)\n",
      "  Using cached pip-20.3.3-py2.py3-none-any.whl (1.5 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\n",
      "DEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -q ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "text = widgets.Textarea()\n",
    "label = widgets.Label()\n",
    "display(label, text)\n",
    "\n",
    "def func(change):\n",
    "    probs = model.predict_proba(change.new, top_k=10)\n",
    "    label.value = ' ' + '\\t'.join([word for prob, word in probs])\n",
    "\n",
    "text.observe(func, names='value')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "5d2c1c838f224a209fe110f4e04e38c2": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "bd2bf182fc5e4c189d32113bb3014f92": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
