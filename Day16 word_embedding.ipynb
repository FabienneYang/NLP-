{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 詞庫手法優缺點\n",
    "# 詞庫手法為創建包含大量字詞的詞庫，將相同意思字詞(同義字)或相似意思字詞(相似字)分類在相同群組。\n",
    "\n",
    "\"\"\"\n",
    "優點:  \n",
    "    一個大的詞庫對自然語言理解，人工智慧的各方面研究都具有重要的價值。通過它，人們可以測試各種關於人類認知能力的理論模型。\n",
    "    手工構建詞典的優點之一是便於創建更為豐富的詞條資訊，其次是便於控制\n",
    "\n",
    "\n",
    "缺點:  \n",
    "    建立詞庫需要大量人力與時間成本, 無法辨識新產生的詞 (ex：當我塑膠, 須以人工更新與維護詞庫\n",
    "    缺乏跟語義處理的細節相匹配的句法資訊\n",
    "    意義分辨方面的困難阻礙了有效利用WordNet中的語義資訊。只有先依靠手工選擇了概念，使得要查找的詞語的意義已知，這種情況下，WordNet中的語義關係資訊才對提高檢索結果有幫助。\n",
    "    WordNet缺乏有關兩個相關詞之間語義距離的資訊\n",
    "    EX.more stew than steak，其中“more ... than”是一個格式，用來連接兩個語義上相關的詞語。在這個例子中，兩個名詞（stew和steak）分屬6個同義詞集合（synset），顯然這無法反映出它們真實的語義距離\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共現矩陣優缺點\n",
    "# 根據分佈假說，相似的字詞會有類似的上下文，因此我們可以透過計數周圍(window)的字詞來表達特定字詞的向量。\n",
    "\n",
    "\"\"\"\n",
    "優點:\n",
    "    訓練速度快,充分利用了全局的統計資訊\n",
    "\n",
    "缺點:\n",
    "    向量空間結構沒有達到最最佳化，在單詞相似度任務上表現不好\n",
    "    隨著字典的擴充，共現矩陣的大小也會改變\n",
    "    共現矩陣十分稀疏，其中大部分區域都為0\n",
    "    十分依賴大型的語料進行訓練\n",
    "\n",
    "    共現矩陣雖然考慮了上下文，其的元素代表兩字詞共生的次數，但這些「原始」次數並非良好的計數方式，會有以下的缺點：\n",
    "        矩陣維度龐大，需要大量的內存\n",
    "        對高頻詞效果較差（ex: “the apple“可能經常出現，但”the”跟”apple”的關聯性是不高的）\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#請問為何需要對共現矩陣或PPMI進行SVD降維?\n",
    "\"\"\"\n",
    "在機器學習中，若輸入(如詞向量)維度太高，會需要增加麼模型的複雜度(如增加參數量)，來學習資料的特徵，\n",
    "為了使複雜的模型保有良好的表現，就需要更大量的資料。 \n",
    "詞向量因為文本字詞一般較為龐大，因此計數手法產生詞向量的維度也會較大，\n",
    "而降維就是刪減向量的維度，在刪減維度的過程中，要盡量保存原有向量的重要資訊，已達成：\n",
    "\n",
    "使用較簡潔的模型達到學習資料特徵的效果\n",
    "降低資料的雜訊\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.7071067811865475\n"
     ]
    }
   ],
   "source": [
    "# 實作cosine similarity\n",
    "# 在比較兩個詞向量的相似度時可以使用cosine similarity: $$ similarity(x,y) = \\frac{x \\cdot y}{||x||||y||} = \\frac{x_1y_1+...+x_ny_n}{\\sqrt{x_1^2+...+x_n^2}\\sqrt{y_1^2+...+y_n^2}} $$\n",
    "\n",
    "# 請實作cosine similarity並計算共現矩陣課程範例中you向量([0,1,0,0,0,0,0])與I([0,1,0,1,0,0,0])向量的相似度\n",
    "\n",
    "import numpy as np\n",
    "I = np.array([0,1,0,0,0,0,0])\n",
    "You = np.array([0,1,0,1,0,0,0])\n",
    "\n",
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    dot = sum(a*b for a, b in zip(x, y))\n",
    "    norm_a = sum(a*a for a in x) ** 0.5\n",
    "    norm_b = sum(b*b for b in y) ** 0.5\n",
    "\n",
    "    # Cosine similarity\n",
    "    cos_sim = dot / (norm_a*norm_b)\n",
    "    return cos_sim\n",
    "\n",
    "print(f\"Similarity: {cos_similarity(I, You)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
